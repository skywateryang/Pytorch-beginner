{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64ba5f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "daa9ac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19022f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_dataloader = DataLoader(training_data, batch_size=100,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0df23e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
    "        self.fc1 = nn.Linear(5*5*16, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = X.view(-1, 5*5*16)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "        return F.log_softmax(X, dim=1)\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fec195e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6f0d6e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 total correct: 47670.0 loss: 326.36219312250614\n",
      "epoch: 2 total correct: 51985.0 loss: 215.94076070189476\n",
      "epoch: 3 total correct: 52774.0 loss: 195.52665321528912\n",
      "epoch: 4 total correct: 53121.0 loss: 184.171044588089\n",
      "epoch: 5 total correct: 53563.0 loss: 175.72666830569506\n",
      "epoch: 6 total correct: 53839.0 loss: 167.72783072292805\n",
      "epoch: 7 total correct: 54085.0 loss: 160.86262968927622\n",
      "epoch: 8 total correct: 54159.0 loss: 158.8448846936226\n",
      "epoch: 9 total correct: 54219.0 loss: 157.03925355523825\n",
      "epoch: 10 total correct: 54327.0 loss: 155.1128320991993\n"
     ]
    }
   ],
   "source": [
    "tb = SummaryWriter()\n",
    "\n",
    "network = NeuralNetwork()\n",
    "images, labels = next(iter(train_dataloader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "tb.add_image('images', grid)\n",
    "tb.add_graph(network, images)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss, total_correct= 0,0\n",
    "    for X, y in train_dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct+= (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    tb.add_scalar('Loss',total_loss,epoch)\n",
    "    tb.add_scalar('Number Correct',total_correct,epoch)\n",
    "    tb.add_scalar('Accuracy',total_correct/len(train_dataloader.dataset),epoch)\n",
    "    \n",
    "    tb.add_scalars('Loss vs Correct', {'Loss':total_loss,\n",
    "                                                            'Correct':total_correct }, epoch)\n",
    "    \n",
    "    tb.add_histogram('conv1.bias', network.conv1.bias,epoch)\n",
    "    tb.add_histogram('conv1.weight', network.conv1.weight,epoch)\n",
    "    \n",
    "    print(\"epoch:\", epoch+1, \"total correct:\", total_correct, \"loss:\", total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7bf0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
